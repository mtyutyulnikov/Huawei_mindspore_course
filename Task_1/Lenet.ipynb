{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8868cc5-3555-47b9-a247-d6bb74e24df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MindSpore version:  1.6.1\n",
      "The result of multiplication calculation is correct, MindSpore has been installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "mindspore.run_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6a7d0-3b6d-4106-a1bc-9144e6b683b6",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595e9e84-1a9b-4d33-a8f0-5d36de93cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from mindspore import context\n",
    "\n",
    "parser = argparse.ArgumentParser(description='MindSpore LeNet Example')\n",
    "parser.add_argument('--device_target', type=str, default=\"CPU\", choices=['Ascend', 'GPU', 'CPU'])\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=args.device_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2757e797-24f1-4ef9-979e-04874eeaccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_dataset(dataset_url, path):\n",
    "    filename = dataset_url.split(\"/\")[-1]\n",
    "    save_path = os.path.join(path, filename)\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    res = requests.get(dataset_url, stream=True, verify=False)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        for chunk in res.iter_content(chunk_size=512):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "train_path = \"datasets/MNIST_Data/train\"\n",
    "test_path = \"datasets/MNIST_Data/test\"\n",
    "\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-labels-idx1-ubyte\", train_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-images-idx3-ubyte\", train_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-labels-idx1-ubyte\", test_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-images-idx3-ubyte\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e62651-9a5b-4f46-b66c-6145f1b3ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore import dtype as mstype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a160e8db-1d68-43f9-936b-28943d17a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    # Define the dataset.\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "\n",
    "    # Define the mapping to be operated.\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)\n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.int32)\n",
    "\n",
    "    # Use the map function to apply data operations to the dataset.\n",
    "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=[resize_op, rescale_op, rescale_nml_op, hwc2chw_op], input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "\n",
    "    # Perform shuffle, batch and repeat operations.\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(count=repeat_size)\n",
    "\n",
    "    return mnist_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633467c1-17f6-4880-8c23-49fa23b466ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.ops import ImageSummary, TensorSummary\n",
    "\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    \"\"\"\n",
    "    Lenet network structure\n",
    "    \"\"\"\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Define the required operation.\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.image_summary = ImageSummary()\n",
    "        self.tensor_summary = TensorSummary()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # Use the defined operation to construct a forward network.\n",
    "        self.image_summary(\"image\", x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        self.tensor_summary(\"tensor\", x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the network.\n",
    "net = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d91b73-eaca-47a3-aa86-db8f5860724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function.\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = nn.Momentum(net.trainable_params(), learning_rate=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a104882d-bf5a-40db-816d-5f03115319e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "# Set model saving parameters.\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "# Use model saving parameters.\n",
    "ckpoint = ModelCheckpoint(prefix=\"checkpoint_lenet\", config=config_ck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bd8809-a7ae-4dd4-9809-0991c804a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor, SummaryCollector\n",
    "from mindspore import Model\n",
    "\n",
    "def train_net(model, epoch_size, data_path, repeat_size, ckpoint_cb, sink_mode):\n",
    "    \"\"\"Define a training method.\"\"\"\n",
    "    # Load the training dataset.\n",
    "    ds_train = create_dataset(os.path.join(data_path, \"train\"), 32, repeat_size)\n",
    "    \n",
    "    \n",
    "    summary_collector = SummaryCollector(summary_dir='./summary_dir', collect_freq=1)\n",
    "    \n",
    "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor(125), summary_collector], dataset_sink_mode=sink_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f27e8d9-ad61-4226-959c-64b59a9bd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(model, data_path):\n",
    "    \"\"\"Define a validation method.\"\"\"\n",
    "    ds_eval = create_dataset(os.path.join(data_path, \"test\"))\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    print(\"{}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033fa736-8ca4-49f9-954f-f8d885c17bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 125, loss is 2.2912356853485107\n",
      "epoch: 1 step: 250, loss is 2.2832140922546387\n",
      "epoch: 1 step: 375, loss is 2.325075387954712\n",
      "epoch: 1 step: 500, loss is 2.3050506114959717\n",
      "epoch: 1 step: 625, loss is 2.3073058128356934\n",
      "epoch: 1 step: 750, loss is 2.3034279346466064\n",
      "epoch: 1 step: 875, loss is 2.2556819915771484\n",
      "epoch: 1 step: 1000, loss is 0.5600167512893677\n",
      "epoch: 1 step: 1125, loss is 0.3073117434978485\n",
      "epoch: 1 step: 1250, loss is 0.13296988606452942\n",
      "epoch: 1 step: 1375, loss is 0.0675698071718216\n",
      "epoch: 1 step: 1500, loss is 0.14693346619606018\n",
      "epoch: 1 step: 1625, loss is 0.20583535730838776\n",
      "epoch: 1 step: 1750, loss is 0.11089009791612625\n",
      "epoch: 1 step: 1875, loss is 0.08111844211816788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] ME(23273:139766403094336,MainProcess):2022-04-13-20:57:58.770.962 [mindspore/train/callback/_summary_collector.py:592] Write meta data /home/misha/mindspore/summary_dir/ckpt_dir/train_metadata.json failed, detail: [Errno 13] Permission denied: '/home/misha/mindspore/summary_dir/ckpt_dir/train_metadata.json'\n",
      "[WARNING] MD(23273,7f1de6ced740,python3.9):2022-04-13-20:57:58.871.085 [mindspore/ccsrc/minddata/dataset/engine/consumers/tree_consumer.cc:68] RegisterProfilingManager] Dataset Profiling is already enabled for a different data pipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9638421474358975}\n"
     ]
    }
   ],
   "source": [
    "from mindspore.profiler import Profiler\n",
    "profiler = Profiler(output_path = './summary_dir/profiler_data')\n",
    "\n",
    "train_epoch = 1\n",
    "mnist_path = \"./datasets/MNIST_Data\"\n",
    "dataset_size = 1\n",
    "model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\n",
    "train_net(model, train_epoch, mnist_path, dataset_size, ckpoint, False)\n",
    "profiler.analyse()\n",
    "\n",
    "test_net(model, mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1886418d-9a8c-479b-a7cb-7fc823d4030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "# Load the saved model for testing.\n",
    "param_dict = load_checkpoint(\"checkpoint_lenet-1_1875.ckpt\")\n",
    "# Load parameters to the network.\n",
    "load_param_into_net(net, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4682510e-2d9a-4edd-97ef-b2d80cf3ec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(23273,7f1de6ced740,python3.9):2022-04-13-20:57:59.708.792 [mindspore/ccsrc/minddata/dataset/engine/consumers/tree_consumer.cc:68] RegisterProfilingManager] Dataset Profiling is already enabled for a different data pipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"6\", Actual: \"6\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "\n",
    "# Define a test dataset. If batch_size is set to 1, an image is obtained.\n",
    "ds_test = create_dataset(os.path.join(mnist_path, \"test\"), batch_size=1).create_dict_iterator()\n",
    "data = next(ds_test)\n",
    "\n",
    "# `images` indicates the test image, and `labels` indicates the actual classification of the test image.\n",
    "images = data[\"image\"].asnumpy()\n",
    "labels = data[\"label\"].asnumpy()\n",
    "\n",
    "# Use the model.predict function to predict the classification of the image.\n",
    "output = model.predict(Tensor(data['image']))\n",
    "predicted = np.argmax(output.asnumpy(), axis=1)\n",
    "\n",
    "# Output the predicted classification and the actual classification.\n",
    "print(f'Predicted: \"{predicted[0]}\", Actual: \"{labels[0]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276913e3-8e08-4d47-a9b4-fa0bd355604a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d23e6ed-0e5a-438e-bef6-46fae45f3837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing MindInsight on port 8080. (pid 18345, Use \"mindinsight stop --port 8080\" to stop it.) Web address: http://127.0.0.1:8080\n"
     ]
    }
   ],
   "source": [
    "!mindinsight start --summary-base-dir ./summary_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1996254-77c5-41b5-afa7-fffa59d7d545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
